{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Judicial Integrity Analysis - Example Walkthrough\n",
    "\n",
    "This notebook demonstrates how to use the Judicial Integrity Analysis package\n",
    "to analyze judges in Arizona (Phase 1 target state).\n",
    "\n",
    "## Contents\n",
    "1. Data Collection\n",
    "2. Preprocessing\n",
    "3. Corruption Analysis\n",
    "4. Ethics Evaluation\n",
    "5. Sentencing Bias Detection\n",
    "6. Partisanship Assessment\n",
    "7. Composite Integrity Summary\n",
    "8. Visualization\n",
    "9. Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Import modules\n",
    "from judicial_integrity_analysis.src.data_acquisition import JudicialDataAggregator\n",
    "from judicial_integrity_analysis.src.preprocessing import JudicialDataPreprocessor\n",
    "from judicial_integrity_analysis.src.analysis import (\n",
    "    JudicialIntegrityAnalyzer,\n",
    "    SentencingDisparityAnalyzer,\n",
    ")\n",
    "from judicial_integrity_analysis.src.visualization import JudicialVisualizer\n",
    "from judicial_integrity_analysis.src.report_generator import ReportGenerator\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "First, we collect judicial data for Arizona. This requires API access to CourtListener.\n",
    "If you don't have an API token, the client will use unauthenticated access with lower rate limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize aggregator for Arizona\n",
    "aggregator = JudicialDataAggregator(\n",
    "    state='az',\n",
    "    data_dir='../data',\n",
    "    # courtlistener_token='your_token_here'  # Optional\n",
    ")\n",
    "\n",
    "# Collect data (limit for demo purposes)\n",
    "raw_data = aggregator.collect_all(max_judges=10)\n",
    "\n",
    "print(f\"Federal judges: {len(raw_data.get('federal_judges', []))}\")\n",
    "print(f\"State judges: {len(raw_data.get('state_judges', []))}\")\n",
    "print(f\"Disciplinary records: {len(raw_data.get('disciplinary_records', []))}\")\n",
    "print(f\"Performance reviews: {len(raw_data.get('performance_reviews', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "Clean and normalize the collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = JudicialDataPreprocessor(raw_data)\n",
    "preprocessor.preprocess_all()\n",
    "\n",
    "if preprocessor.judges is not None:\n",
    "    print(f\"Preprocessed {len(preprocessor.judges)} judges\")\n",
    "    display(preprocessor.judges.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis\n",
    "\n",
    "Run the four-dimensional integrity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = JudicialIntegrityAnalyzer(\n",
    "    judges_df=preprocessor.judges,\n",
    "    disciplinary_df=preprocessor.disciplinary_records,\n",
    "    performance_df=preprocessor.performance_reviews,\n",
    "    sentencing_df=preprocessor.sentencing_data,\n",
    ")\n",
    "\n",
    "# Corruption indicators\n",
    "corruption = analyzer.analyze_corruption_indicators()\n",
    "print(\"Corruption Risk Indicators:\")\n",
    "display(corruption.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethics evaluation\n",
    "ethics = analyzer.analyze_ethics_indicators()\n",
    "print(\"Ethics Indicators:\")\n",
    "display(ethics.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partisanship assessment\n",
    "partisanship = analyzer.analyze_partisanship_indicators()\n",
    "print(\"Partisanship Indicators:\")\n",
    "display(partisanship.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite integrity summary\n",
    "summary = analyzer.compute_integrity_summary()\n",
    "print(\"Integrity Summary:\")\n",
    "display(summary.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text report\n",
    "print(analyzer.generate_text_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization\n",
    "\n",
    "Create visual dashboards of the analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = JudicialVisualizer(figsize=(12, 8))\n",
    "\n",
    "# Risk tier distribution\n",
    "if not summary.empty:\n",
    "    fig = viz.plot_risk_tier_distribution(summary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrity scores\n",
    "if not summary.empty:\n",
    "    fig = viz.plot_integrity_scores(summary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partisanship by appointer\n",
    "if not partisanship.empty:\n",
    "    fig = viz.plot_partisanship_by_appointer(partisanship)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Report Generation\n",
    "\n",
    "Generate publication-ready Markdown reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter = ReportGenerator(state='az', output_dir='../output/reports/az')\n",
    "\n",
    "# State summary report\n",
    "report = reporter.generate_state_summary(\n",
    "    judges_df=preprocessor.judges if preprocessor.judges is not None else pd.DataFrame(),\n",
    "    integrity_summary=summary,\n",
    ")\n",
    "print(report[:1000] + '\\n...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the full Judicial Integrity Analysis workflow:\n",
    "\n",
    "1. **Data Collection**: Gathered judge data from CourtListener and state sources\n",
    "2. **Preprocessing**: Normalized and structured heterogeneous data\n",
    "3. **Corruption Analysis**: Assessed risk from disciplinary actions and financial disclosures\n",
    "4. **Ethics Evaluation**: Scored based on performance reviews\n",
    "5. **Bias Detection**: Analyzed sentencing disparities (when data available)\n",
    "6. **Partisanship Assessment**: Examined appointment backgrounds\n",
    "7. **Composite Scoring**: Combined all dimensions into integrity summary\n",
    "8. **Visualization**: Created dashboards and charts\n",
    "9. **Report Generation**: Produced publication-ready Markdown reports\n",
    "\n",
    "For command-line usage, see `main.py`. For LLM-assisted auditing, configure `OPENROUTER_API_KEY`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
